[03/13 08:41:44][INFO] train_net.py:  518: Train with config:
[03/13 08:41:44][INFO] train_net.py:  519: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'COLOR_RND_GRAYSCALE': 0.0,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'NUM_VIEWS': 6,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/scratch/naman/slowfast/data/daad/dipx/trainval/',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': True,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'DAADMViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 7,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 16,
          'DIM_MUL': [[1, 2.0], [3, 2.0], [14, 2.0]],
          'DIM_MUL_IN_ATT': True,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.2,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [[1, 2.0], [3, 2.0], [14, 2.0]],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': [3, 3, 3],
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[0, 1, 1, 1],
                            [1, 1, 2, 2],
                            [2, 1, 1, 1],
                            [3, 1, 2, 2],
                            [4, 1, 1, 1],
                            [5, 1, 1, 1],
                            [6, 1, 1, 1],
                            [7, 1, 1, 1],
                            [8, 1, 1, 1],
                            [9, 1, 1, 1],
                            [10, 1, 1, 1],
                            [11, 1, 1, 1],
                            [12, 1, 1, 1],
                            [13, 1, 1, 1],
                            [14, 1, 2, 2],
                            [15, 1, 1, 1]],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': True,
          'REL_POS_TEMPORAL': True,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': True,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': False,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 1e-06,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 200,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 30.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.05,
            'ZERO_WD_1D_PARAM': True},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 4,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'daad',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 5,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 2,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 10,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'daad',
           'ENABLE': True,
           'EVAL_PERIOD': 10,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': False},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[03/13 08:41:47][INFO] misc.py:  187: Model:
DAADMViT(
  (x1_patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (x2_patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (x3_patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (x4_patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (x5_patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (x6_patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (x1_projection): Linear(in_features=96, out_features=96, bias=True)
  (x2_projection): Linear(in_features=96, out_features=96, bias=True)
  (x3_projection): Linear(in_features=96, out_features=96, bias=True)
  (x4_projection): Linear(in_features=96, out_features=96, bias=True)
  (x5_projection): Linear(in_features=96, out_features=96, bias=True)
  (x6_projection): Linear(in_features=96, out_features=96, bias=True)
  (blocks): ModuleList(
    (0): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=288, bias=True)
        (proj): Linear(in_features=96, out_features=96, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=384, out_features=96, bias=True)
      )
    )
    (1): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
      (proj): Linear(in_features=96, out_features=192, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (2): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
    )
    (3): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
      (proj): Linear(in_features=192, out_features=384, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (4): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (5): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (6): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (7): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (8): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (9): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (10): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (11): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (12): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (13): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (14): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
      (proj): Linear(in_features=384, out_features=768, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (15): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (head): TransformerBasicHead(
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=1536, out_features=7, bias=True)
    (act): Softmax(dim=1)
  )
)
[03/13 08:41:47][INFO] misc.py:  189: Params: 34,509,031
[03/13 08:41:47][INFO] misc.py:  190: Mem: 0.12891435623168945 MB
[03/13 08:41:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 164 time(s)
[03/13 08:41:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::norm encountered 1 time(s)
[03/13 08:41:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::clamp_min encountered 1 time(s)
[03/13 08:41:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::expand_as encountered 1 time(s)
[03/13 08:41:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 137 time(s)
[03/13 08:41:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 978 time(s)
[03/13 08:41:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 192 time(s)
[03/13 08:41:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 128 time(s)
[03/13 08:41:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 33 time(s)
[03/13 08:41:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 32 time(s)
[03/13 08:41:52][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 6 time(s)
[03/13 08:41:52][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.1.drop_path, blocks.10.drop_path, blocks.11.drop_path, blocks.12.drop_path, blocks.13.drop_path, blocks.14.drop_path, blocks.15.drop_path, blocks.2.drop_path, blocks.3.drop_path, blocks.4.drop_path, blocks.5.drop_path, blocks.6.drop_path, blocks.7.drop_path, blocks.8.drop_path, blocks.9.drop_path
[03/13 08:41:52][INFO] misc.py:  192: Flops: 134.54901384 G
[03/13 08:41:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 164 time(s)
[03/13 08:41:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::norm encountered 1 time(s)
[03/13 08:41:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::clamp_min encountered 1 time(s)
[03/13 08:41:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::expand_as encountered 1 time(s)
[03/13 08:41:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 137 time(s)
[03/13 08:41:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 162 time(s)
[03/13 08:41:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 978 time(s)
[03/13 08:41:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 192 time(s)
[03/13 08:41:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 128 time(s)
[03/13 08:41:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 33 time(s)
[03/13 08:41:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 32 time(s)
[03/13 08:41:56][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 6 time(s)
[03/13 08:41:56][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.1.drop_path, blocks.10.drop_path, blocks.11.drop_path, blocks.12.drop_path, blocks.13.drop_path, blocks.14.drop_path, blocks.15.drop_path, blocks.2.drop_path, blocks.3.drop_path, blocks.4.drop_path, blocks.5.drop_path, blocks.6.drop_path, blocks.7.drop_path, blocks.8.drop_path, blocks.9.drop_path
[03/13 08:41:56][INFO] misc.py:  193: Activations: 521.301817 M
[03/13 08:41:56][INFO] misc.py:  198: nvidia-smi
[03/13 08:41:56][INFO] daad.py:   99: Constructing DAAD train...
[03/13 08:41:56][INFO] daad.py:  171: Constructing DAAD dataloader (size: 1097 skip_rows 0) from /scratch/naman/slowfast/data/daad/dipx/trainval/train.csv
[03/13 08:41:56][INFO] daad.py:   99: Constructing DAAD val...
[03/13 08:41:56][INFO] daad.py:  171: Constructing DAAD dataloader (size: 313 skip_rows 0) from /scratch/naman/slowfast/data/daad/dipx/trainval/val.csv
[03/13 08:41:56][INFO] train_net.py:  611: Start epoch: 1
[03/13 08:42:14][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:43:30][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:43:32][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:43:34][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:43:36][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:44:21][INFO] train_net.py:  518: Train with config:
[03/13 08:44:21][INFO] train_net.py:  519: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',
         'COLOR_JITTER': 0.4,
         'ENABLE': True,
         'GEN_MASK_LOADER': False,
         'INTERPOLATION': 'bicubic',
         'MASK_FRAMES': False,
         'MASK_RATIO': 0.0,
         'MASK_TUBE': False,
         'MASK_WINDOW_SIZE': [8, 7, 7],
         'MAX_MASK_PATCHES_PER_BLOCK': None,
         'NUM_SAMPLE': 2,
         'RE_COUNT': 1,
         'RE_MODE': 'pixel',
         'RE_PROB': 0.25,
         'RE_SPLIT': False},
 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'BGR': False,
         'DETECTION_SCORE_THRESH': 0.9,
         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',
         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',
         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',
         'FULL_TEST_ON_VAL': False,
         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',
         'IMG_PROC_BACKEND': 'cv2',
         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',
         'TEST_FORCE_FLIP': False,
         'TEST_LISTS': ['val.csv'],
         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],
         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],
         'TRAIN_LISTS': ['train.csv'],
         'TRAIN_PCA_JITTER_ONLY': True,
         'TRAIN_PREDICT_BOX_LISTS': [],
         'TRAIN_USE_COLOR_AUGMENTATION': False},
 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),
 'BN': {'GLOBAL_SYNC': False,
        'NORM_TYPE': 'batchnorm',
        'NUM_BATCHES_PRECISE': 200,
        'NUM_SPLITS': 1,
        'NUM_SYNC_DEVICES': 1,
        'USE_PRECISE_STATS': False,
        'WEIGHT_DECAY': 0.0},
 'CONTRASTIVE': {'BN_MLP': False,
                 'BN_SYNC_MLP': False,
                 'DELTA_CLIPS_MAX': inf,
                 'DELTA_CLIPS_MIN': -inf,
                 'DIM': 128,
                 'INTERP_MEMORY': False,
                 'KNN_ON': True,
                 'LENGTH': 239975,
                 'LOCAL_SHUFFLE_BN': True,
                 'MEM_TYPE': '1d',
                 'MLP_DIM': 2048,
                 'MOCO_MULTI_VIEW_QUEUE': False,
                 'MOMENTUM': 0.5,
                 'MOMENTUM_ANNEALING': False,
                 'NUM_CLASSES_DOWNSTREAM': 400,
                 'NUM_MLP_LAYERS': 1,
                 'PREDICTOR_DEPTHS': [],
                 'QUEUE_LEN': 65536,
                 'SEQUENTIAL': False,
                 'SIMCLR_DIST_ON': True,
                 'SWAV_QEUE_LEN': 0,
                 'T': 0.07,
                 'TYPE': 'mem'},
 'DATA': {'COLOR_RND_GRAYSCALE': 0.0,
          'DECODING_BACKEND': 'torchvision',
          'DECODING_SHORT_SIZE': 256,
          'DUMMY_LOAD': False,
          'ENSEMBLE_METHOD': 'sum',
          'IN22K_TRAINVAL': False,
          'IN22k_VAL_IN1K': '',
          'INPUT_CHANNEL_NUM': [3],
          'INV_UNIFORM_SAMPLE': False,
          'IN_VAL_CROP_RATIO': 0.875,
          'LOADER_CHUNK_OVERALL_SIZE': 0,
          'LOADER_CHUNK_SIZE': 0,
          'MEAN': [0.45, 0.45, 0.45],
          'MULTI_LABEL': False,
          'NUM_FRAMES': 16,
          'NUM_VIEWS': 6,
          'PATH_LABEL_SEPARATOR': ' ',
          'PATH_PREFIX': '',
          'PATH_TO_DATA_DIR': '/scratch/naman/slowfast/data/daad/dipx/trainval/',
          'PATH_TO_PRELOAD_IMDB': '',
          'RANDOM_FLIP': True,
          'REVERSE_INPUT_CHANNEL': False,
          'SAMPLING_RATE': 4,
          'SKIP_ROWS': 0,
          'SSL_BLUR_SIGMA_MAX': [0.0, 2.0],
          'SSL_BLUR_SIGMA_MIN': [0.0, 0.1],
          'SSL_COLOR_BRI_CON_SAT': [0.4, 0.4, 0.4],
          'SSL_COLOR_HUE': 0.1,
          'SSL_COLOR_JITTER': False,
          'SSL_MOCOV2_AUG': False,
          'STD': [0.225, 0.225, 0.225],
          'TARGET_FPS': 30,
          'TEST_CROP_SIZE': 224,
          'TIME_DIFF_PROB': 0.0,
          'TRAIN_CROP_NUM_SPATIAL': 1,
          'TRAIN_CROP_NUM_TEMPORAL': 1,
          'TRAIN_CROP_SIZE': 224,
          'TRAIN_JITTER_ASPECT_RELATIVE': [0.75, 1.3333],
          'TRAIN_JITTER_FPS': 0.0,
          'TRAIN_JITTER_MOTION_SHIFT': False,
          'TRAIN_JITTER_SCALES': [256, 320],
          'TRAIN_JITTER_SCALES_RELATIVE': [0.08, 1.0],
          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],
          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],
                               [-0.5808, -0.0045, -0.814],
                               [-0.5836, -0.6948, 0.4203]],
          'USE_OFFSET_SAMPLING': True},
 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,
                 'NUM_WORKERS': 8,
                 'PIN_MEMORY': True},
 'DEMO': {'BUFFER_SIZE': 0,
          'CLIP_VIS_SIZE': 10,
          'COMMON_CLASS_NAMES': ['watch (a person)',
                                 'talk to (e.g., self, a person, a group)',
                                 'listen to (a person)',
                                 'touch (an object)',
                                 'carry/hold (an object)',
                                 'walk',
                                 'sit',
                                 'lie/sleep',
                                 'bend/bow (at the waist)'],
          'COMMON_CLASS_THRES': 0.7,
          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',
          'DETECTRON2_THRESH': 0.9,
          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',
          'DISPLAY_HEIGHT': 0,
          'DISPLAY_WIDTH': 0,
          'ENABLE': False,
          'FPS': 30,
          'GT_BOXES': '',
          'INPUT_FORMAT': 'BGR',
          'INPUT_VIDEO': '',
          'LABEL_FILE_PATH': '',
          'NUM_CLIPS_SKIP': 0,
          'NUM_VIS_INSTANCES': 2,
          'OUTPUT_FILE': '',
          'OUTPUT_FPS': -1,
          'PREDS_BOXES': '',
          'SLOWMO': 1,
          'STARTING_SECOND': 900,
          'THREAD_ENABLE': False,
          'UNCOMMON_CLASS_THRES': 0.3,
          'VIS_MODE': 'thres',
          'WEBCAM': -1},
 'DETECTION': {'ALIGNED': True,
               'ENABLE': False,
               'ROI_XFORM_RESOLUTION': 7,
               'SPATIAL_SCALE_FACTOR': 16},
 'DIST_BACKEND': 'nccl',
 'LOG_MODEL_INFO': True,
 'LOG_PERIOD': 1,
 'MASK': {'DECODER_DEPTH': 0,
          'DECODER_EMBED_DIM': 512,
          'DECODER_SEP_POS_EMBED': False,
          'DEC_KV_KERNEL': [],
          'DEC_KV_STRIDE': [],
          'ENABLE': False,
          'HEAD_TYPE': 'separate',
          'MAE_ON': False,
          'MAE_RND_MASK': False,
          'NORM_PRED_PIXEL': True,
          'PER_FRAME_MASKING': False,
          'PRED_HOG': False,
          'PRETRAIN_DEPTH': [15],
          'SCALE_INIT_BY_DEPTH': False,
          'TIME_STRIDE_LOSS': True},
 'MIXUP': {'ALPHA': 0.8,
           'CUTMIX_ALPHA': 1.0,
           'ENABLE': True,
           'LABEL_SMOOTH_VALUE': 0.1,
           'PROB': 1.0,
           'SWITCH_PROB': 0.5},
 'MODEL': {'ACT_CHECKPOINT': False,
           'ARCH': 'mvit',
           'DETACH_FINAL_FC': False,
           'DROPCONNECT_RATE': 0.0,
           'DROPOUT_RATE': 0.5,
           'FC_INIT_STD': 0.01,
           'FP16_ALLREDUCE': False,
           'FROZEN_BN': False,
           'HEAD_ACT': 'softmax',
           'LOSS_FUNC': 'soft_cross_entropy',
           'MODEL_NAME': 'DAADMViT',
           'MULTI_PATHWAY_ARCH': ['slowfast'],
           'NUM_CLASSES': 7,
           'SINGLE_PATHWAY_ARCH': ['2d',
                                   'c2d',
                                   'i3d',
                                   'slow',
                                   'x3d',
                                   'mvit',
                                   'maskmvit']},
 'MULTIGRID': {'BN_BASE_SIZE': 8,
               'DEFAULT_B': 0,
               'DEFAULT_S': 0,
               'DEFAULT_T': 0,
               'EPOCH_FACTOR': 1.5,
               'EVAL_FREQ': 3,
               'LONG_CYCLE': False,
               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),
                                      (0.5, 0.7071067811865476),
                                      (0.5, 1),
                                      (1, 1)],
               'LONG_CYCLE_SAMPLING_RATE': 0,
               'SHORT_CYCLE': False,
               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},
 'MVIT': {'CLS_EMBED_ON': True,
          'DEPTH': 16,
          'DIM_MUL': [[1, 2.0], [3, 2.0], [14, 2.0]],
          'DIM_MUL_IN_ATT': True,
          'DROPOUT_RATE': 0.0,
          'DROPPATH_RATE': 0.2,
          'EMBED_DIM': 96,
          'HEAD_INIT_SCALE': 1.0,
          'HEAD_MUL': [[1, 2.0], [3, 2.0], [14, 2.0]],
          'LAYER_SCALE_INIT_VALUE': 0.0,
          'MLP_RATIO': 4.0,
          'MODE': 'conv',
          'NORM': 'layernorm',
          'NORM_STEM': False,
          'NUM_HEADS': 1,
          'PATCH_2D': False,
          'PATCH_KERNEL': [3, 7, 7],
          'PATCH_PADDING': [1, 3, 3],
          'PATCH_STRIDE': [2, 4, 4],
          'POOL_FIRST': False,
          'POOL_KVQ_KERNEL': [3, 3, 3],
          'POOL_KV_STRIDE': [],
          'POOL_KV_STRIDE_ADAPTIVE': [1, 8, 8],
          'POOL_Q_STRIDE': [[0, 1, 1, 1],
                            [1, 1, 2, 2],
                            [2, 1, 1, 1],
                            [3, 1, 2, 2],
                            [4, 1, 1, 1],
                            [5, 1, 1, 1],
                            [6, 1, 1, 1],
                            [7, 1, 1, 1],
                            [8, 1, 1, 1],
                            [9, 1, 1, 1],
                            [10, 1, 1, 1],
                            [11, 1, 1, 1],
                            [12, 1, 1, 1],
                            [13, 1, 1, 1],
                            [14, 1, 2, 2],
                            [15, 1, 1, 1]],
          'QKV_BIAS': True,
          'REL_POS_SPATIAL': True,
          'REL_POS_TEMPORAL': True,
          'REL_POS_ZERO_INIT': False,
          'RESIDUAL_POOLING': True,
          'REV': {'BUFFER_LAYERS': [],
                  'ENABLE': False,
                  'PRE_Q_FUSION': 'avg',
                  'RESPATH_FUSE': 'concat',
                  'RES_PATH': 'conv'},
          'SEPARATE_QKV': False,
          'SEP_POS_EMBED': False,
          'USE_ABS_POS': False,
          'USE_FIXED_SINCOS_POS': False,
          'USE_MEAN_POOLING': False,
          'ZERO_DECAY_POS_CLS': False},
 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],
              'INSTANTIATION': 'dot_product',
              'LOCATION': [[[]], [[]], [[]], [[]]],
              'POOL': [[[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]],
                       [[1, 2, 2], [1, 2, 2]]]},
 'NUM_GPUS': 1,
 'NUM_SHARDS': 1,
 'OUTPUT_DIR': '.',
 'RESNET': {'DEPTH': 50,
            'INPLACE_RELU': True,
            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],
            'NUM_GROUPS': 1,
            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],
            'SPATIAL_STRIDES': [[1], [2], [2], [2]],
            'STRIDE_1X1': False,
            'TRANS_FUNC': 'bottleneck_transform',
            'WIDTH_PER_GROUP': 64,
            'ZERO_INIT_FINAL_BN': False,
            'ZERO_INIT_FINAL_CONV': False},
 'RNG_SEED': 0,
 'SHARD_ID': 0,
 'SLOWFAST': {'ALPHA': 8,
              'BETA_INV': 8,
              'FUSION_CONV_CHANNEL_RATIO': 2,
              'FUSION_KERNEL_SZ': 5},
 'SOLVER': {'BASE_LR': 0.0001,
            'BASE_LR_SCALE_NUM_SHARDS': True,
            'BETAS': (0.9, 0.999),
            'CLIP_GRAD_L2NORM': 1.0,
            'CLIP_GRAD_VAL': None,
            'COSINE_AFTER_WARMUP': True,
            'COSINE_END_LR': 1e-06,
            'DAMPENING': 0.0,
            'GAMMA': 0.1,
            'LARS_ON': False,
            'LAYER_DECAY': 1.0,
            'LRS': [],
            'LR_POLICY': 'cosine',
            'MAX_EPOCH': 200,
            'MOMENTUM': 0.9,
            'NESTEROV': True,
            'OPTIMIZING_METHOD': 'adamw',
            'STEPS': [],
            'STEP_SIZE': 1,
            'WARMUP_EPOCHS': 30.0,
            'WARMUP_FACTOR': 0.1,
            'WARMUP_START_LR': 1e-06,
            'WEIGHT_DECAY': 0.05,
            'ZERO_WD_1D_PARAM': True},
 'TASK': '',
 'TENSORBOARD': {'CATEGORIES_PATH': '',
                 'CLASS_NAMES_PATH': '',
                 'CONFUSION_MATRIX': {'ENABLE': False,
                                      'FIGSIZE': [8, 8],
                                      'SUBSET_PATH': ''},
                 'ENABLE': False,
                 'HISTOGRAM': {'ENABLE': False,
                               'FIGSIZE': [8, 8],
                               'SUBSET_PATH': '',
                               'TOPK': 10},
                 'LOG_DIR': '',
                 'MODEL_VIS': {'ACTIVATIONS': False,
                               'COLORMAP': 'Pastel2',
                               'ENABLE': False,
                               'GRAD_CAM': {'COLORMAP': 'viridis',
                                            'ENABLE': True,
                                            'LAYER_LIST': [],
                                            'USE_TRUE_LABEL': False},
                               'INPUT_VIDEO': False,
                               'LAYER_LIST': [],
                               'MODEL_WEIGHTS': False,
                               'TOPK_PREDS': 1},
                 'PREDICTIONS_PATH': '',
                 'WRONG_PRED_VIS': {'ENABLE': False,
                                    'SUBSET_PATH': '',
                                    'TAG': 'Incorrectly classified videos.'}},
 'TEST': {'BATCH_SIZE': 4,
          'CHECKPOINT_FILE_PATH': '',
          'CHECKPOINT_TYPE': 'pytorch',
          'DATASET': 'daad',
          'ENABLE': True,
          'NUM_ENSEMBLE_VIEWS': 5,
          'NUM_SPATIAL_CROPS': 1,
          'NUM_TEMPORAL_CLIPS': [],
          'SAVE_RESULTS_PATH': ''},
 'TRAIN': {'AUTO_RESUME': True,
           'BATCH_SIZE': 1,
           'CHECKPOINT_CLEAR_NAME_PATTERN': (),
           'CHECKPOINT_EPOCH_RESET': False,
           'CHECKPOINT_FILE_PATH': '',
           'CHECKPOINT_INFLATE': False,
           'CHECKPOINT_IN_INIT': False,
           'CHECKPOINT_PERIOD': 10,
           'CHECKPOINT_TYPE': 'pytorch',
           'DATASET': 'daad',
           'ENABLE': True,
           'EVAL_PERIOD': 10,
           'KILL_LOSS_EXPLOSION_FACTOR': 0.0,
           'MIXED_PRECISION': False},
 'VIS_MASK': CfgNode({'ENABLE': False}),
 'X3D': {'BN_LIN5': False,
         'BOTTLENECK_FACTOR': 1.0,
         'CHANNELWISE_3x3x3': True,
         'DEPTH_FACTOR': 1.0,
         'DIM_C1': 12,
         'DIM_C5': 2048,
         'SCALE_RES2': False,
         'WIDTH_FACTOR': 1.0}}
[03/13 08:44:23][INFO] misc.py:  187: Model:
DAADMViT(
  (x1_patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (x2_patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (x3_patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (x4_patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (x5_patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (x6_patch_embed): PatchEmbed(
    (proj): Conv3d(3, 96, kernel_size=(3, 7, 7), stride=(2, 4, 4), padding=(1, 3, 3))
  )
  (x1_projection): Linear(in_features=96, out_features=96, bias=True)
  (x2_projection): Linear(in_features=96, out_features=96, bias=True)
  (x3_projection): Linear(in_features=96, out_features=96, bias=True)
  (x4_projection): Linear(in_features=96, out_features=96, bias=True)
  (x5_projection): Linear(in_features=96, out_features=96, bias=True)
  (x6_projection): Linear(in_features=96, out_features=96, bias=True)
  (blocks): ModuleList(
    (0): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=288, bias=True)
        (proj): Linear(in_features=96, out_features=96, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 8, 8), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=384, out_features=96, bias=True)
      )
    )
    (1): MultiScaleBlock(
      (norm1): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=96, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
      (proj): Linear(in_features=96, out_features=192, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (2): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=576, bias=True)
        (proj): Linear(in_features=192, out_features=192, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 4, 4), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=768, out_features=192, bias=True)
      )
    )
    (3): MultiScaleBlock(
      (norm1): LayerNorm((192,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=192, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
      (proj): Linear(in_features=192, out_features=384, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (4): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (5): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (6): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (7): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (8): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (9): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (10): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (11): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (12): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (13): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=1152, bias=True)
        (proj): Linear(in_features=384, out_features=384, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=1536, out_features=384, bias=True)
      )
    )
    (14): MultiScaleBlock(
      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=384, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
      (proj): Linear(in_features=384, out_features=768, bias=True)
      (pool_skip): MaxPool3d(kernel_size=[1, 3, 3], stride=[1, 2, 2], padding=[0, 1, 1], dilation=1, ceil_mode=False)
    )
    (15): MultiScaleBlock(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): MultiScaleAttention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (pool_q): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_q): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_k): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_k): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
        (pool_v): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=96, bias=False)
        (norm_v): LayerNorm((96,), eps=1e-06, elementwise_affine=True)
      )
      (drop_path): DropPath()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (head): TransformerBasicHead(
    (dropout): Dropout(p=0.5, inplace=False)
    (projection): Linear(in_features=1536, out_features=7, bias=True)
    (act): Softmax(dim=1)
  )
)
[03/13 08:44:23][INFO] misc.py:  189: Params: 34,509,031
[03/13 08:44:23][INFO] misc.py:  190: Mem: 0.12891435623168945 MB
[03/13 08:44:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 164 time(s)
[03/13 08:44:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::norm encountered 1 time(s)
[03/13 08:44:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::clamp_min encountered 1 time(s)
[03/13 08:44:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::expand_as encountered 1 time(s)
[03/13 08:44:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 137 time(s)
[03/13 08:44:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 978 time(s)
[03/13 08:44:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 192 time(s)
[03/13 08:44:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 128 time(s)
[03/13 08:44:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 33 time(s)
[03/13 08:44:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 32 time(s)
[03/13 08:44:28][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 6 time(s)
[03/13 08:44:28][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.1.drop_path, blocks.10.drop_path, blocks.11.drop_path, blocks.12.drop_path, blocks.13.drop_path, blocks.14.drop_path, blocks.15.drop_path, blocks.2.drop_path, blocks.3.drop_path, blocks.4.drop_path, blocks.5.drop_path, blocks.6.drop_path, blocks.7.drop_path, blocks.8.drop_path, blocks.9.drop_path
[03/13 08:44:28][INFO] misc.py:  192: Flops: 134.54901384 G
[03/13 08:44:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::add encountered 164 time(s)
[03/13 08:44:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::norm encountered 1 time(s)
[03/13 08:44:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::clamp_min encountered 1 time(s)
[03/13 08:44:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::expand_as encountered 1 time(s)
[03/13 08:44:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::div encountered 137 time(s)
[03/13 08:44:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::layer_norm encountered 162 time(s)
[03/13 08:44:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::mul encountered 978 time(s)
[03/13 08:44:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::sub encountered 192 time(s)
[03/13 08:44:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::add_ encountered 128 time(s)
[03/13 08:44:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::softmax encountered 33 time(s)
[03/13 08:44:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::gelu encountered 32 time(s)
[03/13 08:44:31][WARNING] jit_analysis.py:  499: Unsupported operator aten::max_pool3d encountered 6 time(s)
[03/13 08:44:31][WARNING] jit_analysis.py:  511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.
blocks.1.drop_path, blocks.10.drop_path, blocks.11.drop_path, blocks.12.drop_path, blocks.13.drop_path, blocks.14.drop_path, blocks.15.drop_path, blocks.2.drop_path, blocks.3.drop_path, blocks.4.drop_path, blocks.5.drop_path, blocks.6.drop_path, blocks.7.drop_path, blocks.8.drop_path, blocks.9.drop_path
[03/13 08:44:31][INFO] misc.py:  193: Activations: 521.301817 M
[03/13 08:44:31][INFO] misc.py:  198: nvidia-smi
[03/13 08:44:32][INFO] daad.py:   99: Constructing DAAD train...
[03/13 08:44:32][INFO] daad.py:  171: Constructing DAAD dataloader (size: 1097 skip_rows 0) from /scratch/naman/slowfast/data/daad/dipx/trainval/train.csv
[03/13 08:44:32][INFO] daad.py:   99: Constructing DAAD val...
[03/13 08:44:32][INFO] daad.py:  171: Constructing DAAD dataloader (size: 313 skip_rows 0) from /scratch/naman/slowfast/data/daad/dipx/trainval/val.csv
[03/13 08:44:32][INFO] train_net.py:  611: Start epoch: 1
[03/13 08:44:48][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:45:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 42.32062, "dt_data": 41.51856, "dt_net": 0.80206, "epoch": "1/200", "eta": "107 days, 11:11:41", "gpu_mem": "6.18G", "grad_norm": 179.44713, "iter": "1/1097", "loss": 1.75739, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:45:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64342, "dt_data": 0.00049, "dt_net": 0.64294, "epoch": "1/200", "eta": "1 day, 15:12:45", "gpu_mem": "6.58G", "grad_norm": 231.89746, "iter": "2/1097", "loss": 2.38136, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:45:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64493, "dt_data": 0.00047, "dt_net": 0.64446, "epoch": "1/200", "eta": "1 day, 15:18:15", "gpu_mem": "6.58G", "grad_norm": 114.13265, "iter": "3/1097", "loss": 0.90931, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:45:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64753, "dt_data": 0.00046, "dt_net": 0.64707, "epoch": "1/200", "eta": "1 day, 15:27:46", "gpu_mem": "6.58G", "grad_norm": 182.32489, "iter": "4/1097", "loss": 2.05505, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:45:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.65005, "dt_data": 0.00048, "dt_net": 0.64957, "epoch": "1/200", "eta": "1 day, 15:36:57", "gpu_mem": "6.58G", "grad_norm": 240.76297, "iter": "5/1097", "loss": 2.63984, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:45:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.65076, "dt_data": 0.00043, "dt_net": 0.65033, "epoch": "1/200", "eta": "1 day, 15:39:32", "gpu_mem": "6.58G", "grad_norm": 161.04364, "iter": "6/1097", "loss": 1.78501, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:45:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64041, "dt_data": 0.00040, "dt_net": 0.63999, "epoch": "1/200", "eta": "1 day, 15:01:41", "gpu_mem": "6.58G", "grad_norm": 191.43274, "iter": "7/1097", "loss": 3.07600, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:45:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64778, "dt_data": 0.00051, "dt_net": 0.64727, "epoch": "1/200", "eta": "1 day, 15:28:38", "gpu_mem": "6.58G", "grad_norm": 155.50934, "iter": "8/1097", "loss": 1.36159, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:45:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 21.20506, "dt_data": 20.52397, "dt_net": 0.68108, "epoch": "1/200", "eta": "53 days, 20:16:38", "gpu_mem": "6.58G", "grad_norm": 232.84610, "iter": "9/1097", "loss": 2.65661, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:45:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64292, "dt_data": 0.00054, "dt_net": 0.64238, "epoch": "1/200", "eta": "1 day, 15:10:50", "gpu_mem": "6.58G", "grad_norm": 172.50618, "iter": "10/1097", "loss": 1.86842, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:45:41][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.66527, "dt_data": 0.00095, "dt_net": 0.66431, "epoch": "1/200", "eta": "1 day, 16:32:32", "gpu_mem": "6.58G", "grad_norm": 153.00850, "iter": "11/1097", "loss": 1.59994, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:45:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.65129, "dt_data": 0.00064, "dt_net": 0.65065, "epoch": "1/200", "eta": "1 day, 15:41:24", "gpu_mem": "6.58G", "grad_norm": 211.13635, "iter": "12/1097", "loss": 2.10666, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:45:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64467, "dt_data": 0.00055, "dt_net": 0.64412, "epoch": "1/200", "eta": "1 day, 15:17:12", "gpu_mem": "6.58G", "grad_norm": 209.00160, "iter": "13/1097", "loss": 2.64494, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:45:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64280, "dt_data": 0.00055, "dt_net": 0.64226, "epoch": "1/200", "eta": "1 day, 15:10:22", "gpu_mem": "6.58G", "grad_norm": 217.78246, "iter": "14/1097", "loss": 3.08608, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:45:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64158, "dt_data": 0.00055, "dt_net": 0.64103, "epoch": "1/200", "eta": "1 day, 15:05:52", "gpu_mem": "6.58G", "grad_norm": 193.54463, "iter": "15/1097", "loss": 2.93479, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:45:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64249, "dt_data": 0.00058, "dt_net": 0.64191, "epoch": "1/200", "eta": "1 day, 15:09:12", "gpu_mem": "6.58G", "grad_norm": 183.72679, "iter": "16/1097", "loss": 2.15564, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:45:57][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:46:05][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:46:12][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:46:19][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:46:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 41.83441, "dt_data": 41.15112, "dt_net": 0.68329, "epoch": "1/200", "eta": "106 days, 5:22:38", "gpu_mem": "6.58G", "grad_norm": 168.05453, "iter": "17/1097", "loss": 1.36564, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:46:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.67108, "dt_data": 0.00080, "dt_net": 0.67028, "epoch": "1/200", "eta": "1 day, 16:53:43", "gpu_mem": "6.58G", "grad_norm": 174.29776, "iter": "18/1097", "loss": 1.60715, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:46:27][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.66093, "dt_data": 0.00055, "dt_net": 0.66038, "epoch": "1/200", "eta": "1 day, 16:16:34", "gpu_mem": "6.58G", "grad_norm": 143.35182, "iter": "19/1097", "loss": 1.15253, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:46:28][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.66097, "dt_data": 0.00043, "dt_net": 0.66054, "epoch": "1/200", "eta": "1 day, 16:16:43", "gpu_mem": "6.58G", "grad_norm": 206.40254, "iter": "20/1097", "loss": 2.64223, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:46:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.66219, "dt_data": 0.00057, "dt_net": 0.66162, "epoch": "1/200", "eta": "1 day, 16:21:09", "gpu_mem": "6.58G", "grad_norm": 180.44196, "iter": "21/1097", "loss": 2.97366, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:46:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.66358, "dt_data": 0.00071, "dt_net": 0.66287, "epoch": "1/200", "eta": "1 day, 16:26:14", "gpu_mem": "6.58G", "grad_norm": 236.33234, "iter": "22/1097", "loss": 3.99632, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:46:30][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.65702, "dt_data": 0.00045, "dt_net": 0.65657, "epoch": "1/200", "eta": "1 day, 16:02:15", "gpu_mem": "6.58G", "grad_norm": 222.40765, "iter": "23/1097", "loss": 2.69189, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:46:31][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.65934, "dt_data": 0.00036, "dt_net": 0.65897, "epoch": "1/200", "eta": "1 day, 16:10:42", "gpu_mem": "6.58G", "grad_norm": 233.39371, "iter": "24/1097", "loss": 3.42892, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:46:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 16.02388, "dt_data": 15.34297, "dt_net": 0.68091, "epoch": "1/200", "eta": "40 days, 16:27:19", "gpu_mem": "6.58G", "grad_norm": 228.20073, "iter": "25/1097", "loss": 2.36382, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:46:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64731, "dt_data": 0.00080, "dt_net": 0.64651, "epoch": "1/200", "eta": "1 day, 15:26:43", "gpu_mem": "6.58G", "grad_norm": 197.60664, "iter": "26/1097", "loss": 1.74075, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:46:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64440, "dt_data": 0.00050, "dt_net": 0.64390, "epoch": "1/200", "eta": "1 day, 15:16:03", "gpu_mem": "6.58G", "grad_norm": 236.87451, "iter": "27/1097", "loss": 2.85721, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:46:49][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64669, "dt_data": 0.00054, "dt_net": 0.64615, "epoch": "1/200", "eta": "1 day, 15:24:24", "gpu_mem": "6.58G", "grad_norm": 197.54820, "iter": "28/1097", "loss": 3.33373, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:46:49][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64718, "dt_data": 0.00048, "dt_net": 0.64670, "epoch": "1/200", "eta": "1 day, 15:26:13", "gpu_mem": "6.58G", "grad_norm": 149.86848, "iter": "29/1097", "loss": 1.47088, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:46:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64851, "dt_data": 0.00050, "dt_net": 0.64801, "epoch": "1/200", "eta": "1 day, 15:31:04", "gpu_mem": "6.58G", "grad_norm": 129.95155, "iter": "30/1097", "loss": 1.44555, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:46:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64869, "dt_data": 0.00046, "dt_net": 0.64822, "epoch": "1/200", "eta": "1 day, 15:31:41", "gpu_mem": "6.58G", "grad_norm": 141.98691, "iter": "31/1097", "loss": 1.56036, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:46:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64392, "dt_data": 0.00057, "dt_net": 0.64335, "epoch": "1/200", "eta": "1 day, 15:14:14", "gpu_mem": "6.58G", "grad_norm": 204.21330, "iter": "32/1097", "loss": 2.23464, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:47:13][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:47:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 23.69742, "dt_data": 23.01156, "dt_net": 0.68585, "epoch": "1/200", "eta": "60 days, 4:00:30", "gpu_mem": "6.58G", "grad_norm": 244.24762, "iter": "33/1097", "loss": 2.48408, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:47:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.65569, "dt_data": 0.00086, "dt_net": 0.65483, "epoch": "1/200", "eta": "1 day, 15:57:16", "gpu_mem": "6.58G", "grad_norm": 206.88902, "iter": "34/1097", "loss": 2.91784, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:47:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64718, "dt_data": 0.00056, "dt_net": 0.64663, "epoch": "1/200", "eta": "1 day, 15:26:09", "gpu_mem": "6.58G", "grad_norm": 194.82883, "iter": "35/1097", "loss": 1.72861, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:47:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64076, "dt_data": 0.00056, "dt_net": 0.64020, "epoch": "1/200", "eta": "1 day, 15:02:39", "gpu_mem": "6.58G", "grad_norm": 219.91612, "iter": "36/1097", "loss": 2.49874, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:47:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64324, "dt_data": 0.00327, "dt_net": 0.63997, "epoch": "1/200", "eta": "1 day, 15:11:43", "gpu_mem": "6.58G", "grad_norm": 181.57820, "iter": "37/1097", "loss": 1.95315, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:47:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63961, "dt_data": 0.00047, "dt_net": 0.63914, "epoch": "1/200", "eta": "1 day, 14:58:26", "gpu_mem": "6.58G", "grad_norm": 187.00488, "iter": "38/1097", "loss": 2.43937, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:47:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64077, "dt_data": 0.00043, "dt_net": 0.64034, "epoch": "1/200", "eta": "1 day, 15:02:40", "gpu_mem": "6.58G", "grad_norm": 231.77838, "iter": "39/1097", "loss": 2.44424, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:47:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64033, "dt_data": 0.00043, "dt_net": 0.63989, "epoch": "1/200", "eta": "1 day, 15:01:02", "gpu_mem": "6.58G", "grad_norm": 131.95494, "iter": "40/1097", "loss": 2.30363, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:47:23][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:47:28][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:47:37][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:47:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 30.57942, "dt_data": 29.90346, "dt_net": 0.67596, "epoch": "1/200", "eta": "77 days, 15:17:51", "gpu_mem": "6.58G", "grad_norm": 159.38699, "iter": "41/1097", "loss": 1.26876, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:47:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64424, "dt_data": 0.00047, "dt_net": 0.64375, "epoch": "1/200", "eta": "1 day, 15:15:20", "gpu_mem": "6.58G", "grad_norm": 248.30138, "iter": "42/1097", "loss": 3.25945, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:47:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64336, "dt_data": 0.00044, "dt_net": 0.64291, "epoch": "1/200", "eta": "1 day, 15:12:04", "gpu_mem": "6.58G", "grad_norm": 224.35400, "iter": "43/1097", "loss": 3.71350, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:47:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64518, "dt_data": 0.00056, "dt_net": 0.64463, "epoch": "1/200", "eta": "1 day, 15:18:45", "gpu_mem": "6.58G", "grad_norm": 195.85680, "iter": "44/1097", "loss": 2.77255, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:47:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64276, "dt_data": 0.00047, "dt_net": 0.64229, "epoch": "1/200", "eta": "1 day, 15:09:51", "gpu_mem": "6.58G", "grad_norm": 261.51416, "iter": "45/1097", "loss": 3.03864, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:47:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64900, "dt_data": 0.00043, "dt_net": 0.64856, "epoch": "1/200", "eta": "1 day, 15:32:39", "gpu_mem": "6.58G", "grad_norm": 118.29679, "iter": "46/1097", "loss": 1.16543, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:47:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64015, "dt_data": 0.00039, "dt_net": 0.63976, "epoch": "1/200", "eta": "1 day, 15:00:19", "gpu_mem": "6.58G", "grad_norm": 169.24403, "iter": "47/1097", "loss": 1.50467, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:47:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64036, "dt_data": 0.00059, "dt_net": 0.63977, "epoch": "1/200", "eta": "1 day, 15:01:03", "gpu_mem": "6.58G", "grad_norm": 167.25087, "iter": "48/1097", "loss": 1.95003, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:48:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 15.44636, "dt_data": 14.76030, "dt_net": 0.68606, "epoch": "1/200", "eta": "39 days, 5:09:34", "gpu_mem": "6.58G", "grad_norm": 190.86047, "iter": "49/1097", "loss": 2.73053, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:48:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64098, "dt_data": 0.00062, "dt_net": 0.64036, "epoch": "1/200", "eta": "1 day, 15:03:19", "gpu_mem": "6.58G", "grad_norm": 159.89084, "iter": "50/1097", "loss": 1.51491, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:48:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64415, "dt_data": 0.00054, "dt_net": 0.64361, "epoch": "1/200", "eta": "1 day, 15:14:53", "gpu_mem": "6.58G", "grad_norm": 195.56601, "iter": "51/1097", "loss": 2.01575, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:48:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64457, "dt_data": 0.00043, "dt_net": 0.64414, "epoch": "1/200", "eta": "1 day, 15:16:24", "gpu_mem": "6.58G", "grad_norm": 225.05225, "iter": "52/1097", "loss": 2.50970, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:48:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63889, "dt_data": 0.00047, "dt_net": 0.63842, "epoch": "1/200", "eta": "1 day, 14:55:37", "gpu_mem": "6.58G", "grad_norm": 197.65135, "iter": "53/1097", "loss": 1.90151, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:48:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64050, "dt_data": 0.00040, "dt_net": 0.64010, "epoch": "1/200", "eta": "1 day, 15:01:30", "gpu_mem": "6.58G", "grad_norm": 129.29059, "iter": "54/1097", "loss": 1.42527, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:48:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64125, "dt_data": 0.00037, "dt_net": 0.64088, "epoch": "1/200", "eta": "1 day, 15:04:15", "gpu_mem": "6.58G", "grad_norm": 135.87984, "iter": "55/1097", "loss": 1.34993, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:48:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63912, "dt_data": 0.00039, "dt_net": 0.63874, "epoch": "1/200", "eta": "1 day, 14:56:28", "gpu_mem": "6.58G", "grad_norm": 191.92014, "iter": "56/1097", "loss": 2.62227, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:48:22][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:48:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 27.12658, "dt_data": 26.43834, "dt_net": 0.68823, "epoch": "1/200", "eta": "68 days, 20:47:05", "gpu_mem": "6.58G", "grad_norm": 182.46059, "iter": "57/1097", "loss": 2.37044, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:48:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63585, "dt_data": 0.00036, "dt_net": 0.63549, "epoch": "1/200", "eta": "1 day, 14:44:28", "gpu_mem": "6.58G", "grad_norm": 164.33472, "iter": "58/1097", "loss": 1.28344, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:48:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63358, "dt_data": 0.00049, "dt_net": 0.63309, "epoch": "1/200", "eta": "1 day, 14:36:10", "gpu_mem": "6.58G", "grad_norm": 213.52032, "iter": "59/1097", "loss": 1.96297, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:48:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63829, "dt_data": 0.00043, "dt_net": 0.63786, "epoch": "1/200", "eta": "1 day, 14:53:21", "gpu_mem": "6.58G", "grad_norm": 238.04771, "iter": "60/1097", "loss": 2.74432, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:48:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63647, "dt_data": 0.00048, "dt_net": 0.63599, "epoch": "1/200", "eta": "1 day, 14:46:42", "gpu_mem": "6.58G", "grad_norm": 188.00838, "iter": "61/1097", "loss": 1.71277, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:48:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63579, "dt_data": 0.00043, "dt_net": 0.63537, "epoch": "1/200", "eta": "1 day, 14:44:13", "gpu_mem": "6.58G", "grad_norm": 232.02521, "iter": "62/1097", "loss": 2.16408, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:48:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63507, "dt_data": 0.00037, "dt_net": 0.63470, "epoch": "1/200", "eta": "1 day, 14:41:35", "gpu_mem": "6.58G", "grad_norm": 146.64911, "iter": "63/1097", "loss": 1.44662, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:48:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 6.03117, "dt_data": 5.34546, "dt_net": 0.68570, "epoch": "1/200", "eta": "15 days, 7:27:32", "gpu_mem": "6.58G", "grad_norm": 215.08876, "iter": "64/1097", "loss": 2.05622, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:49:06][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:49:15][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 23.59017, "dt_data": 22.90698, "dt_net": 0.68319, "epoch": "1/200", "eta": "59 days, 21:15:50", "gpu_mem": "6.58G", "grad_norm": 244.64154, "iter": "65/1097", "loss": 2.47463, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:49:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64174, "dt_data": 0.00042, "dt_net": 0.64132, "epoch": "1/200", "eta": "1 day, 15:05:54", "gpu_mem": "6.58G", "grad_norm": 212.33833, "iter": "66/1097", "loss": 2.38451, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:49:16][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64107, "dt_data": 0.00049, "dt_net": 0.64058, "epoch": "1/200", "eta": "1 day, 15:03:27", "gpu_mem": "6.58G", "grad_norm": 197.19098, "iter": "67/1097", "loss": 2.43058, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:49:17][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63995, "dt_data": 0.00065, "dt_net": 0.63930, "epoch": "1/200", "eta": "1 day, 14:59:22", "gpu_mem": "6.58G", "grad_norm": 143.03079, "iter": "68/1097", "loss": 2.21319, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:49:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63867, "dt_data": 0.00049, "dt_net": 0.63818, "epoch": "1/200", "eta": "1 day, 14:54:39", "gpu_mem": "6.58G", "grad_norm": 190.59895, "iter": "69/1097", "loss": 1.87546, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:49:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63974, "dt_data": 0.00040, "dt_net": 0.63933, "epoch": "1/200", "eta": "1 day, 14:58:33", "gpu_mem": "6.58G", "grad_norm": 186.96167, "iter": "70/1097", "loss": 2.83996, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:49:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64342, "dt_data": 0.00037, "dt_net": 0.64305, "epoch": "1/200", "eta": "1 day, 15:12:00", "gpu_mem": "6.58G", "grad_norm": 200.32002, "iter": "71/1097", "loss": 2.51394, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:49:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63799, "dt_data": 0.00048, "dt_net": 0.63751, "epoch": "1/200", "eta": "1 day, 14:52:09", "gpu_mem": "6.58G", "grad_norm": 208.20694, "iter": "72/1097", "loss": 2.52388, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:49:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 22.52114, "dt_data": 21.82796, "dt_net": 0.69317, "epoch": "1/200", "eta": "57 days, 4:04:54", "gpu_mem": "6.58G", "grad_norm": 87.93329, "iter": "73/1097", "loss": 0.90261, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:49:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64044, "dt_data": 0.00039, "dt_net": 0.64006, "epoch": "1/200", "eta": "1 day, 15:01:05", "gpu_mem": "6.58G", "grad_norm": 216.85434, "iter": "74/1097", "loss": 2.73242, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:49:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64737, "dt_data": 0.00051, "dt_net": 0.64686, "epoch": "1/200", "eta": "1 day, 15:26:24", "gpu_mem": "6.58G", "grad_norm": 285.28366, "iter": "75/1097", "loss": 3.79378, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:49:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63893, "dt_data": 0.00044, "dt_net": 0.63848, "epoch": "1/200", "eta": "1 day, 14:55:31", "gpu_mem": "6.58G", "grad_norm": 197.13792, "iter": "76/1097", "loss": 1.79614, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:49:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63921, "dt_data": 0.00048, "dt_net": 0.63873, "epoch": "1/200", "eta": "1 day, 14:56:33", "gpu_mem": "6.58G", "grad_norm": 240.64174, "iter": "77/1097", "loss": 2.37494, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:49:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64532, "dt_data": 0.00039, "dt_net": 0.64494, "epoch": "1/200", "eta": "1 day, 15:18:53", "gpu_mem": "6.58G", "grad_norm": 181.34116, "iter": "78/1097", "loss": 1.56397, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:49:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64531, "dt_data": 0.00038, "dt_net": 0.64493, "epoch": "1/200", "eta": "1 day, 15:18:50", "gpu_mem": "6.58G", "grad_norm": 187.01051, "iter": "79/1097", "loss": 1.51274, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:49:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 2.28099, "dt_data": 1.63007, "dt_net": 0.65092, "epoch": "1/200", "eta": "5 days, 18:57:47", "gpu_mem": "6.58G", "grad_norm": 88.73431, "iter": "80/1097", "loss": 0.87800, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:50:03][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 14.63375, "dt_data": 13.96513, "dt_net": 0.66862, "epoch": "1/200", "eta": "37 days, 3:31:00", "gpu_mem": "6.58G", "grad_norm": 254.42635, "iter": "81/1097", "loss": 2.99780, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:50:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63936, "dt_data": 0.00039, "dt_net": 0.63897, "epoch": "1/200", "eta": "1 day, 14:57:03", "gpu_mem": "6.58G", "grad_norm": 198.01341, "iter": "82/1097", "loss": 1.41797, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:50:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63902, "dt_data": 0.00044, "dt_net": 0.63858, "epoch": "1/200", "eta": "1 day, 14:55:48", "gpu_mem": "6.58G", "grad_norm": 199.70198, "iter": "83/1097", "loss": 1.97137, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:50:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63989, "dt_data": 0.00039, "dt_net": 0.63950, "epoch": "1/200", "eta": "1 day, 14:58:58", "gpu_mem": "6.58G", "grad_norm": 167.37675, "iter": "84/1097", "loss": 2.42509, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:50:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64243, "dt_data": 0.00048, "dt_net": 0.64195, "epoch": "1/200", "eta": "1 day, 15:08:14", "gpu_mem": "6.58G", "grad_norm": 206.11436, "iter": "85/1097", "loss": 2.62636, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:50:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64705, "dt_data": 0.00036, "dt_net": 0.64668, "epoch": "1/200", "eta": "1 day, 15:25:06", "gpu_mem": "6.58G", "grad_norm": 108.87841, "iter": "86/1097", "loss": 0.93608, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:50:07][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64255, "dt_data": 0.00038, "dt_net": 0.64217, "epoch": "1/200", "eta": "1 day, 15:08:38", "gpu_mem": "6.58G", "grad_norm": 197.58754, "iter": "87/1097", "loss": 2.34695, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:50:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 1.93140, "dt_data": 1.28176, "dt_net": 0.64963, "epoch": "1/200", "eta": "4 days, 21:39:39", "gpu_mem": "6.58G", "grad_norm": 200.87137, "iter": "88/1097", "loss": 3.08842, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:50:17][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:50:29][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 20.57177, "dt_data": 19.89765, "dt_net": 0.67412, "epoch": "1/200", "eta": "52 days, 5:13:35", "gpu_mem": "6.58G", "grad_norm": 211.01370, "iter": "89/1097", "loss": 2.06100, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:50:30][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64375, "dt_data": 0.00041, "dt_net": 0.64335, "epoch": "1/200", "eta": "1 day, 15:13:01", "gpu_mem": "6.58G", "grad_norm": 206.78593, "iter": "90/1097", "loss": 3.68195, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:50:31][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64345, "dt_data": 0.00046, "dt_net": 0.64299, "epoch": "1/200", "eta": "1 day, 15:11:54", "gpu_mem": "6.58G", "grad_norm": 227.95753, "iter": "91/1097", "loss": 2.47083, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:50:31][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64059, "dt_data": 0.00037, "dt_net": 0.64022, "epoch": "1/200", "eta": "1 day, 15:01:25", "gpu_mem": "6.58G", "grad_norm": 230.28592, "iter": "92/1097", "loss": 3.17362, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:50:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.65587, "dt_data": 0.00050, "dt_net": 0.65537, "epoch": "1/200", "eta": "1 day, 15:57:16", "gpu_mem": "6.58G", "grad_norm": 249.55307, "iter": "93/1097", "loss": 2.91276, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:50:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64994, "dt_data": 0.00044, "dt_net": 0.64949, "epoch": "1/200", "eta": "1 day, 15:35:34", "gpu_mem": "6.58G", "grad_norm": 202.54878, "iter": "94/1097", "loss": 2.31971, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:50:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64192, "dt_data": 0.00036, "dt_net": 0.64155, "epoch": "1/200", "eta": "1 day, 15:06:15", "gpu_mem": "6.58G", "grad_norm": 211.95088, "iter": "95/1097", "loss": 2.67941, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:50:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 4.40849, "dt_data": 3.73863, "dt_net": 0.66986, "epoch": "1/200", "eta": "11 days, 4:33:19", "gpu_mem": "6.58G", "grad_norm": 205.46600, "iter": "96/1097", "loss": 3.34820, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:50:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 15.92732, "dt_data": 15.24897, "dt_net": 0.67835, "epoch": "1/200", "eta": "40 days, 10:15:08", "gpu_mem": "6.58G", "grad_norm": 194.13365, "iter": "97/1097", "loss": 2.35217, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:50:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 2.64690, "dt_data": 1.97302, "dt_net": 0.67388, "epoch": "1/200", "eta": "6 days, 17:14:29", "gpu_mem": "6.58G", "grad_norm": 189.19624, "iter": "98/1097", "loss": 3.01849, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:50:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64104, "dt_data": 0.00084, "dt_net": 0.64019, "epoch": "1/200", "eta": "1 day, 15:02:59", "gpu_mem": "6.58G", "grad_norm": 140.02309, "iter": "99/1097", "loss": 1.37011, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:50:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64013, "dt_data": 0.00039, "dt_net": 0.63974, "epoch": "1/200", "eta": "1 day, 14:59:41", "gpu_mem": "6.58G", "grad_norm": 168.13510, "iter": "100/1097", "loss": 1.44996, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:50:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63978, "dt_data": 0.00044, "dt_net": 0.63934, "epoch": "1/200", "eta": "1 day, 14:58:22", "gpu_mem": "6.58G", "grad_norm": 123.66419, "iter": "101/1097", "loss": 1.18762, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:50:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64068, "dt_data": 0.00042, "dt_net": 0.64027, "epoch": "1/200", "eta": "1 day, 15:01:40", "gpu_mem": "6.58G", "grad_norm": 202.87564, "iter": "102/1097", "loss": 3.82356, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:50:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64089, "dt_data": 0.00041, "dt_net": 0.64048, "epoch": "1/200", "eta": "1 day, 15:02:25", "gpu_mem": "6.58G", "grad_norm": 246.85143, "iter": "103/1097", "loss": 2.17421, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:51:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 5.88696, "dt_data": 5.21506, "dt_net": 0.67189, "epoch": "1/200", "eta": "14 days, 22:36:25", "gpu_mem": "6.58G", "grad_norm": 176.66530, "iter": "104/1097", "loss": 1.72260, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:51:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 12.62994, "dt_data": 11.96208, "dt_net": 0.66786, "epoch": "1/200", "eta": "32 days, 1:21:22", "gpu_mem": "6.58G", "grad_norm": 203.58035, "iter": "105/1097", "loss": 2.74051, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:51:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 4.83209, "dt_data": 4.16090, "dt_net": 0.67119, "epoch": "1/200", "eta": "12 days, 6:20:48", "gpu_mem": "6.58G", "grad_norm": 221.21835, "iter": "106/1097", "loss": 3.06678, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:51:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64164, "dt_data": 0.00049, "dt_net": 0.64115, "epoch": "1/200", "eta": "1 day, 15:05:07", "gpu_mem": "6.58G", "grad_norm": 193.23143, "iter": "107/1097", "loss": 1.84386, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:51:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64025, "dt_data": 0.00044, "dt_net": 0.63981, "epoch": "1/200", "eta": "1 day, 15:00:01", "gpu_mem": "6.58G", "grad_norm": 206.00684, "iter": "108/1097", "loss": 2.12076, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:51:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63975, "dt_data": 0.00045, "dt_net": 0.63930, "epoch": "1/200", "eta": "1 day, 14:58:11", "gpu_mem": "6.58G", "grad_norm": 216.78189, "iter": "109/1097", "loss": 3.21630, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:51:25][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64244, "dt_data": 0.00042, "dt_net": 0.64201, "epoch": "1/200", "eta": "1 day, 15:08:00", "gpu_mem": "6.58G", "grad_norm": 250.11269, "iter": "110/1097", "loss": 2.79703, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:51:26][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64311, "dt_data": 0.00040, "dt_net": 0.64271, "epoch": "1/200", "eta": "1 day, 15:10:26", "gpu_mem": "6.58G", "grad_norm": 249.27785, "iter": "111/1097", "loss": 3.12807, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 100.00000}
[03/13 08:51:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 8.83707, "dt_data": 8.16591, "dt_net": 0.67116, "epoch": "1/200", "eta": "22 days, 10:17:44", "gpu_mem": "6.58G", "grad_norm": 144.93814, "iter": "112/1097", "loss": 1.73738, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:51:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 18.84323, "dt_data": 18.14245, "dt_net": 0.70078, "epoch": "1/200", "eta": "47 days, 19:47:54", "gpu_mem": "6.58G", "grad_norm": 227.50087, "iter": "113/1097", "loss": 2.54530, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:51:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.65418, "dt_data": 0.00049, "dt_net": 0.65368, "epoch": "1/200", "eta": "1 day, 15:50:51", "gpu_mem": "6.58G", "grad_norm": 235.09026, "iter": "114/1097", "loss": 2.41098, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:51:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.65140, "dt_data": 0.00049, "dt_net": 0.65091, "epoch": "1/200", "eta": "1 day, 15:40:42", "gpu_mem": "6.58G", "grad_norm": 143.65399, "iter": "115/1097", "loss": 1.40271, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:51:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63907, "dt_data": 0.00043, "dt_net": 0.63864, "epoch": "1/200", "eta": "1 day, 14:55:38", "gpu_mem": "6.58G", "grad_norm": 147.47639, "iter": "116/1097", "loss": 1.39728, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:51:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63901, "dt_data": 0.00048, "dt_net": 0.63852, "epoch": "1/200", "eta": "1 day, 14:55:23", "gpu_mem": "6.58G", "grad_norm": 207.88699, "iter": "117/1097", "loss": 1.72579, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:51:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64486, "dt_data": 0.00044, "dt_net": 0.64442, "epoch": "1/200", "eta": "1 day, 15:16:46", "gpu_mem": "6.58G", "grad_norm": 216.29861, "iter": "118/1097", "loss": 2.55708, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:51:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.65146, "dt_data": 0.00047, "dt_net": 0.65100, "epoch": "1/200", "eta": "1 day, 15:40:53", "gpu_mem": "6.58G", "grad_norm": 211.51038, "iter": "119/1097", "loss": 2.53875, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:52:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 7.76406, "dt_data": 7.08040, "dt_net": 0.68365, "epoch": "1/200", "eta": "19 days, 16:55:03", "gpu_mem": "6.58G", "grad_norm": 192.85658, "iter": "120/1097", "loss": 2.28377, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:52:31][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 25.48841, "dt_data": 24.81117, "dt_net": 0.67723, "epoch": "1/200", "eta": "64 days, 16:31:12", "gpu_mem": "6.58G", "grad_norm": 213.52107, "iter": "121/1097", "loss": 1.84536, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:52:31][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63466, "dt_data": 0.00044, "dt_net": 0.63422, "epoch": "1/200", "eta": "1 day, 14:39:27", "gpu_mem": "6.58G", "grad_norm": 243.17822, "iter": "122/1097", "loss": 3.49919, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:52:32][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63315, "dt_data": 0.00030, "dt_net": 0.63285, "epoch": "1/200", "eta": "1 day, 14:33:56", "gpu_mem": "6.58G", "grad_norm": 198.41386, "iter": "123/1097", "loss": 2.79924, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:52:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63471, "dt_data": 0.00041, "dt_net": 0.63430, "epoch": "1/200", "eta": "1 day, 14:39:36", "gpu_mem": "6.58G", "grad_norm": 224.67760, "iter": "124/1097", "loss": 3.75724, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:52:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63833, "dt_data": 0.00052, "dt_net": 0.63781, "epoch": "1/200", "eta": "1 day, 14:52:48", "gpu_mem": "6.58G", "grad_norm": 179.17291, "iter": "125/1097", "loss": 1.52604, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:52:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63434, "dt_data": 0.00045, "dt_net": 0.63390, "epoch": "1/200", "eta": "1 day, 14:38:15", "gpu_mem": "6.58G", "grad_norm": 189.82364, "iter": "126/1097", "loss": 1.92815, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:52:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63393, "dt_data": 0.00039, "dt_net": 0.63353, "epoch": "1/200", "eta": "1 day, 14:36:42", "gpu_mem": "6.58G", "grad_norm": 146.89142, "iter": "127/1097", "loss": 1.47793, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:52:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63473, "dt_data": 0.00043, "dt_net": 0.63431, "epoch": "1/200", "eta": "1 day, 14:39:39", "gpu_mem": "6.58G", "grad_norm": 229.99983, "iter": "128/1097", "loss": 2.52198, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:52:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 19.22029, "dt_data": 18.53783, "dt_net": 0.68246, "epoch": "1/200", "eta": "48 days, 18:40:52", "gpu_mem": "6.58G", "grad_norm": 233.72493, "iter": "129/1097", "loss": 3.49086, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:52:55][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64402, "dt_data": 0.00043, "dt_net": 0.64359, "epoch": "1/200", "eta": "1 day, 15:13:33", "gpu_mem": "6.58G", "grad_norm": 171.52881, "iter": "130/1097", "loss": 2.56455, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:52:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64652, "dt_data": 0.00045, "dt_net": 0.64607, "epoch": "1/200", "eta": "1 day, 15:22:41", "gpu_mem": "6.58G", "grad_norm": 246.88942, "iter": "131/1097", "loss": 2.99966, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 100.00000}
[03/13 08:52:56][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64196, "dt_data": 0.00043, "dt_net": 0.64153, "epoch": "1/200", "eta": "1 day, 15:06:01", "gpu_mem": "6.58G", "grad_norm": 129.88725, "iter": "132/1097", "loss": 1.10852, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:52:57][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64168, "dt_data": 0.00049, "dt_net": 0.64119, "epoch": "1/200", "eta": "1 day, 15:04:59", "gpu_mem": "6.58G", "grad_norm": 210.98288, "iter": "133/1097", "loss": 2.41931, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:52:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64096, "dt_data": 0.00042, "dt_net": 0.64054, "epoch": "1/200", "eta": "1 day, 15:02:19", "gpu_mem": "6.58G", "grad_norm": 154.88164, "iter": "134/1097", "loss": 1.48926, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:52:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64383, "dt_data": 0.00040, "dt_net": 0.64343, "epoch": "1/200", "eta": "1 day, 15:12:49", "gpu_mem": "6.58G", "grad_norm": 190.11766, "iter": "135/1097", "loss": 3.38501, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:52:59][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64659, "dt_data": 0.00066, "dt_net": 0.64593, "epoch": "1/200", "eta": "1 day, 15:22:54", "gpu_mem": "6.58G", "grad_norm": 132.97508, "iter": "136/1097", "loss": 1.26517, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:53:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 20.46745, "dt_data": 19.77877, "dt_net": 0.68868, "epoch": "1/200", "eta": "51 days, 22:35:54", "gpu_mem": "6.58G", "grad_norm": 235.27504, "iter": "137/1097", "loss": 3.14288, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:53:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64165, "dt_data": 0.00078, "dt_net": 0.64087, "epoch": "1/200", "eta": "1 day, 15:04:49", "gpu_mem": "6.58G", "grad_norm": 203.68019, "iter": "138/1097", "loss": 2.61963, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:53:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64041, "dt_data": 0.00055, "dt_net": 0.63986, "epoch": "1/200", "eta": "1 day, 15:00:16", "gpu_mem": "6.58G", "grad_norm": 212.15125, "iter": "139/1097", "loss": 3.71534, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:53:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64024, "dt_data": 0.00044, "dt_net": 0.63979, "epoch": "1/200", "eta": "1 day, 14:59:37", "gpu_mem": "6.58G", "grad_norm": 118.93195, "iter": "140/1097", "loss": 0.96465, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:53:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64263, "dt_data": 0.00049, "dt_net": 0.64214, "epoch": "1/200", "eta": "1 day, 15:08:23", "gpu_mem": "6.58G", "grad_norm": 178.59296, "iter": "141/1097", "loss": 2.05487, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:53:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64066, "dt_data": 0.00044, "dt_net": 0.64021, "epoch": "1/200", "eta": "1 day, 15:01:08", "gpu_mem": "6.58G", "grad_norm": 218.21001, "iter": "142/1097", "loss": 3.50171, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:53:23][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64190, "dt_data": 0.00042, "dt_net": 0.64148, "epoch": "1/200", "eta": "1 day, 15:05:41", "gpu_mem": "6.58G", "grad_norm": 183.06575, "iter": "143/1097", "loss": 2.25988, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:53:24][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64113, "dt_data": 0.00045, "dt_net": 0.64068, "epoch": "1/200", "eta": "1 day, 15:02:52", "gpu_mem": "6.58G", "grad_norm": 210.16547, "iter": "144/1097", "loss": 3.44567, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:53:49][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 25.39560, "dt_data": 24.72534, "dt_net": 0.67026, "epoch": "1/200", "eta": "64 days, 10:41:52", "gpu_mem": "6.58G", "grad_norm": 169.67296, "iter": "145/1097", "loss": 1.96218, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:53:50][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63512, "dt_data": 0.00041, "dt_net": 0.63471, "epoch": "1/200", "eta": "1 day, 14:40:53", "gpu_mem": "6.58G", "grad_norm": 182.44121, "iter": "146/1097", "loss": 2.27974, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:53:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63661, "dt_data": 0.00038, "dt_net": 0.63623, "epoch": "1/200", "eta": "1 day, 14:46:18", "gpu_mem": "6.58G", "grad_norm": 196.68930, "iter": "147/1097", "loss": 1.36899, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:53:51][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63573, "dt_data": 0.00044, "dt_net": 0.63529, "epoch": "1/200", "eta": "1 day, 14:43:05", "gpu_mem": "6.58G", "grad_norm": 180.64320, "iter": "148/1097", "loss": 2.12961, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:53:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63982, "dt_data": 0.00047, "dt_net": 0.63935, "epoch": "1/200", "eta": "1 day, 14:58:01", "gpu_mem": "6.58G", "grad_norm": 155.03197, "iter": "149/1097", "loss": 1.56159, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:53:52][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64062, "dt_data": 0.00042, "dt_net": 0.64020, "epoch": "1/200", "eta": "1 day, 15:00:56", "gpu_mem": "6.58G", "grad_norm": 206.22519, "iter": "150/1097", "loss": 1.92692, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:53:53][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63878, "dt_data": 0.00039, "dt_net": 0.63838, "epoch": "1/200", "eta": "1 day, 14:54:11", "gpu_mem": "6.58G", "grad_norm": 142.32268, "iter": "151/1097", "loss": 1.60688, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:53:54][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63738, "dt_data": 0.00041, "dt_net": 0.63697, "epoch": "1/200", "eta": "1 day, 14:49:03", "gpu_mem": "6.58G", "grad_norm": 216.01701, "iter": "152/1097", "loss": 2.44624, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:54:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 24.09032, "dt_data": 23.40873, "dt_net": 0.68158, "epoch": "1/200", "eta": "61 days, 3:08:49", "gpu_mem": "6.58G", "grad_norm": 201.11063, "iter": "153/1097", "loss": 2.54437, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:54:18][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64245, "dt_data": 0.00040, "dt_net": 0.64205, "epoch": "1/200", "eta": "1 day, 15:07:34", "gpu_mem": "6.58G", "grad_norm": 226.39311, "iter": "154/1097", "loss": 4.01889, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:54:19][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64209, "dt_data": 0.00041, "dt_net": 0.64168, "epoch": "1/200", "eta": "1 day, 15:06:15", "gpu_mem": "6.58G", "grad_norm": 176.52336, "iter": "155/1097", "loss": 1.66520, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:54:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64041, "dt_data": 0.00041, "dt_net": 0.64000, "epoch": "1/200", "eta": "1 day, 15:00:05", "gpu_mem": "6.58G", "grad_norm": 214.19586, "iter": "156/1097", "loss": 2.93918, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:54:20][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64349, "dt_data": 0.00044, "dt_net": 0.64305, "epoch": "1/200", "eta": "1 day, 15:11:21", "gpu_mem": "6.58G", "grad_norm": 216.39682, "iter": "157/1097", "loss": 2.81942, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:54:21][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63970, "dt_data": 0.00046, "dt_net": 0.63923, "epoch": "1/200", "eta": "1 day, 14:57:28", "gpu_mem": "6.58G", "grad_norm": 170.19693, "iter": "158/1097", "loss": 1.64584, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:54:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64561, "dt_data": 0.00041, "dt_net": 0.64520, "epoch": "1/200", "eta": "1 day, 15:19:03", "gpu_mem": "6.58G", "grad_norm": 158.10263, "iter": "159/1097", "loss": 1.98268, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:54:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63981, "dt_data": 0.00038, "dt_net": 0.63943, "epoch": "1/200", "eta": "1 day, 14:57:51", "gpu_mem": "6.58G", "grad_norm": 223.14421, "iter": "160/1097", "loss": 4.29867, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:54:32][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:54:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 20.82105, "dt_data": 20.14746, "dt_net": 0.67360, "epoch": "1/200", "eta": "52 days, 19:59:47", "gpu_mem": "6.58G", "grad_norm": 172.53661, "iter": "161/1097", "loss": 1.86535, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:54:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64632, "dt_data": 0.00041, "dt_net": 0.64591, "epoch": "1/200", "eta": "1 day, 15:21:38", "gpu_mem": "6.58G", "grad_norm": 257.66284, "iter": "162/1097", "loss": 3.95865, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:54:44][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63928, "dt_data": 0.00044, "dt_net": 0.63885, "epoch": "1/200", "eta": "1 day, 14:55:54", "gpu_mem": "6.58G", "grad_norm": 176.63013, "iter": "163/1097", "loss": 2.21462, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:54:45][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64406, "dt_data": 0.00042, "dt_net": 0.64364, "epoch": "1/200", "eta": "1 day, 15:13:20", "gpu_mem": "6.58G", "grad_norm": 240.43010, "iter": "164/1097", "loss": 3.90232, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:54:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64051, "dt_data": 0.00050, "dt_net": 0.64001, "epoch": "1/200", "eta": "1 day, 15:00:22", "gpu_mem": "6.58G", "grad_norm": 182.71748, "iter": "165/1097", "loss": 2.66353, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:54:46][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64242, "dt_data": 0.00048, "dt_net": 0.64194, "epoch": "1/200", "eta": "1 day, 15:07:19", "gpu_mem": "6.58G", "grad_norm": 69.03352, "iter": "166/1097", "loss": 0.75972, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:54:47][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63963, "dt_data": 0.00069, "dt_net": 0.63895, "epoch": "1/200", "eta": "1 day, 14:57:08", "gpu_mem": "6.58G", "grad_norm": 213.17249, "iter": "167/1097", "loss": 2.88397, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:54:48][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64054, "dt_data": 0.00045, "dt_net": 0.64008, "epoch": "1/200", "eta": "1 day, 15:00:26", "gpu_mem": "6.58G", "grad_norm": 196.70035, "iter": "168/1097", "loss": 3.25996, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:55:09][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 21.66814, "dt_data": 20.98894, "dt_net": 0.67920, "epoch": "1/200", "eta": "54 days, 23:32:07", "gpu_mem": "6.58G", "grad_norm": 186.49461, "iter": "169/1097", "loss": 2.47563, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:55:10][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64022, "dt_data": 0.00041, "dt_net": 0.63981, "epoch": "1/200", "eta": "1 day, 14:59:15", "gpu_mem": "6.58G", "grad_norm": 208.06085, "iter": "170/1097", "loss": 2.51609, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:55:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64297, "dt_data": 0.00049, "dt_net": 0.64249, "epoch": "1/200", "eta": "1 day, 15:09:18", "gpu_mem": "6.58G", "grad_norm": 108.12038, "iter": "171/1097", "loss": 0.81359, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:55:11][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64119, "dt_data": 0.00040, "dt_net": 0.64079, "epoch": "1/200", "eta": "1 day, 15:02:46", "gpu_mem": "6.58G", "grad_norm": 212.77298, "iter": "172/1097", "loss": 2.70436, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:55:12][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63993, "dt_data": 0.00027, "dt_net": 0.63966, "epoch": "1/200", "eta": "1 day, 14:58:09", "gpu_mem": "6.58G", "grad_norm": 193.78607, "iter": "173/1097", "loss": 3.50010, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:55:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64009, "dt_data": 0.00038, "dt_net": 0.63971, "epoch": "1/200", "eta": "1 day, 14:58:43", "gpu_mem": "6.58G", "grad_norm": 173.72346, "iter": "174/1097", "loss": 1.81228, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:55:13][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64074, "dt_data": 0.00037, "dt_net": 0.64037, "epoch": "1/200", "eta": "1 day, 15:01:07", "gpu_mem": "6.58G", "grad_norm": 214.32356, "iter": "175/1097", "loss": 3.69214, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:55:14][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64105, "dt_data": 0.00040, "dt_net": 0.64065, "epoch": "1/200", "eta": "1 day, 15:02:12", "gpu_mem": "6.58G", "grad_norm": 188.15944, "iter": "176/1097", "loss": 2.32250, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:55:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 24.41430, "dt_data": 23.74851, "dt_net": 0.66578, "epoch": "1/200", "eta": "61 days, 22:42:55", "gpu_mem": "6.58G", "grad_norm": 144.72533, "iter": "177/1097", "loss": 1.66589, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:55:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63608, "dt_data": 0.00037, "dt_net": 0.63571, "epoch": "1/200", "eta": "1 day, 14:44:03", "gpu_mem": "6.58G", "grad_norm": 161.44080, "iter": "178/1097", "loss": 1.94540, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:55:39][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63896, "dt_data": 0.00040, "dt_net": 0.63856, "epoch": "1/200", "eta": "1 day, 14:54:32", "gpu_mem": "6.58G", "grad_norm": 201.71364, "iter": "179/1097", "loss": 2.65165, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:55:40][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63466, "dt_data": 0.00040, "dt_net": 0.63425, "epoch": "1/200", "eta": "1 day, 14:38:49", "gpu_mem": "6.58G", "grad_norm": 219.31874, "iter": "180/1097", "loss": 2.33823, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:55:41][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63504, "dt_data": 0.00041, "dt_net": 0.63463, "epoch": "1/200", "eta": "1 day, 14:40:13", "gpu_mem": "6.58G", "grad_norm": 179.31721, "iter": "181/1097", "loss": 1.87139, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:55:41][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63386, "dt_data": 0.00040, "dt_net": 0.63346, "epoch": "1/200", "eta": "1 day, 14:35:54", "gpu_mem": "6.58G", "grad_norm": 191.92886, "iter": "182/1097", "loss": 2.74842, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:55:42][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63583, "dt_data": 0.00032, "dt_net": 0.63550, "epoch": "1/200", "eta": "1 day, 14:43:04", "gpu_mem": "6.58G", "grad_norm": 236.47482, "iter": "183/1097", "loss": 2.26110, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:55:43][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63811, "dt_data": 0.00038, "dt_net": 0.63773, "epoch": "1/200", "eta": "1 day, 14:51:24", "gpu_mem": "6.58G", "grad_norm": 212.88615, "iter": "184/1097", "loss": 2.54433, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:56:03][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 20.55704, "dt_data": 19.86208, "dt_net": 0.69495, "epoch": "1/200", "eta": "52 days, 3:46:51", "gpu_mem": "6.58G", "grad_norm": 185.21896, "iter": "185/1097", "loss": 2.61385, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:56:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64338, "dt_data": 0.00036, "dt_net": 0.64302, "epoch": "1/200", "eta": "1 day, 15:10:37", "gpu_mem": "6.58G", "grad_norm": 181.67342, "iter": "186/1097", "loss": 1.81281, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:56:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64184, "dt_data": 0.00038, "dt_net": 0.64146, "epoch": "1/200", "eta": "1 day, 15:05:00", "gpu_mem": "6.58G", "grad_norm": 153.35048, "iter": "187/1097", "loss": 1.21275, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:56:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64370, "dt_data": 0.00049, "dt_net": 0.64321, "epoch": "1/200", "eta": "1 day, 15:11:45", "gpu_mem": "6.58G", "grad_norm": 115.65562, "iter": "188/1097", "loss": 1.10134, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:56:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64347, "dt_data": 0.00040, "dt_net": 0.64308, "epoch": "1/200", "eta": "1 day, 15:10:56", "gpu_mem": "6.58G", "grad_norm": 209.49489, "iter": "189/1097", "loss": 3.39591, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:56:06][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64128, "dt_data": 0.00041, "dt_net": 0.64087, "epoch": "1/200", "eta": "1 day, 15:02:54", "gpu_mem": "6.58G", "grad_norm": 232.34099, "iter": "190/1097", "loss": 2.65800, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:56:07][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.63944, "dt_data": 0.00039, "dt_net": 0.63904, "epoch": "1/200", "eta": "1 day, 14:56:10", "gpu_mem": "6.58G", "grad_norm": 180.07477, "iter": "191/1097", "loss": 2.81795, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:56:08][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64116, "dt_data": 0.00050, "dt_net": 0.64066, "epoch": "1/200", "eta": "1 day, 15:02:28", "gpu_mem": "6.58G", "grad_norm": 160.19844, "iter": "192/1097", "loss": 1.40299, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:56:33][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 25.57924, "dt_data": 24.90802, "dt_net": 0.67122, "epoch": "1/200", "eta": "64 days, 21:32:28", "gpu_mem": "6.58G", "grad_norm": 203.29739, "iter": "193/1097", "loss": 4.04698, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 50.00000}
[03/13 08:56:34][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64063, "dt_data": 0.00044, "dt_net": 0.64019, "epoch": "1/200", "eta": "1 day, 15:00:29", "gpu_mem": "6.58G", "grad_norm": 230.23250, "iter": "194/1097", "loss": 2.37110, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:56:34][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:56:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64239, "dt_data": 0.00038, "dt_net": 0.64201, "epoch": "1/200", "eta": "1 day, 15:06:55", "gpu_mem": "6.58G", "grad_norm": 200.09021, "iter": "195/1097", "loss": 2.46408, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:56:35][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.64304, "dt_data": 0.00038, "dt_net": 0.64266, "epoch": "1/200", "eta": "1 day, 15:09:16", "gpu_mem": "6.58G", "grad_norm": 213.00458, "iter": "196/1097", "loss": 2.89140, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:56:36][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.68672, "dt_data": 0.00046, "dt_net": 0.68626, "epoch": "1/200", "eta": "1 day, 17:48:51", "gpu_mem": "6.58G", "grad_norm": 132.77272, "iter": "197/1097", "loss": 1.28759, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:56:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.67228, "dt_data": 0.00049, "dt_net": 0.67179, "epoch": "1/200", "eta": "1 day, 16:56:04", "gpu_mem": "6.58G", "grad_norm": 199.09598, "iter": "198/1097", "loss": 2.31860, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:56:37][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.67276, "dt_data": 0.00044, "dt_net": 0.67233, "epoch": "1/200", "eta": "1 day, 16:57:50", "gpu_mem": "6.58G", "grad_norm": 182.66844, "iter": "199/1097", "loss": 1.73623, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:56:38][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.67047, "dt_data": 0.00044, "dt_net": 0.67003, "epoch": "1/200", "eta": "1 day, 16:49:26", "gpu_mem": "6.58G", "grad_norm": 160.83925, "iter": "200/1097", "loss": 1.38297, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:56:42][INFO] decoder.py:  340: TV decode FAILED try decode all
[03/13 08:56:58][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 19.80862, "dt_data": 19.09261, "dt_net": 0.71600, "epoch": "1/200", "eta": "50 days, 6:07:09", "gpu_mem": "6.58G", "grad_norm": 125.12784, "iter": "201/1097", "loss": 1.12964, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:57:01][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 3.19471, "dt_data": 2.48346, "dt_net": 0.71125, "epoch": "1/200", "eta": "8 days, 2:31:13", "gpu_mem": "6.58G", "grad_norm": 182.25490, "iter": "202/1097", "loss": 1.95221, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:57:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.67113, "dt_data": 0.00043, "dt_net": 0.67070, "epoch": "1/200", "eta": "1 day, 16:51:50", "gpu_mem": "6.58G", "grad_norm": 236.04895, "iter": "203/1097", "loss": 3.43270, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:57:02][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.66862, "dt_data": 0.00051, "dt_net": 0.66811, "epoch": "1/200", "eta": "1 day, 16:42:39", "gpu_mem": "6.58G", "grad_norm": 180.94870, "iter": "204/1097", "loss": 2.33570, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:57:03][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.66483, "dt_data": 0.00051, "dt_net": 0.66432, "epoch": "1/200", "eta": "1 day, 16:28:47", "gpu_mem": "6.58G", "grad_norm": 155.91592, "iter": "205/1097", "loss": 1.88201, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 50.00000}
[03/13 08:57:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.66951, "dt_data": 0.00053, "dt_net": 0.66898, "epoch": "1/200", "eta": "1 day, 16:45:51", "gpu_mem": "6.58G", "grad_norm": 123.03176, "iter": "206/1097", "loss": 1.09874, "lr": 0.00000, "top1_err": 0.00000, "top5_err": 0.00000}
[03/13 08:57:04][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.66723, "dt_data": 0.00042, "dt_net": 0.66681, "epoch": "1/200", "eta": "1 day, 16:37:32", "gpu_mem": "6.58G", "grad_norm": 184.11176, "iter": "207/1097", "loss": 2.02718, "lr": 0.00000, "top1_err": 50.00000, "top5_err": 0.00000}
[03/13 08:57:05][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 0.67408, "dt_data": 0.00044, "dt_net": 0.67364, "epoch": "1/200", "eta": "1 day, 17:02:32", "gpu_mem": "6.58G", "grad_norm": 178.65096, "iter": "208/1097", "loss": 1.74548, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
[03/13 08:57:22][INFO] logging.py:   98: json_stats: {"_type": "train_iter_", "dt": 16.89381, "dt_data": 16.19196, "dt_net": 0.70185, "epoch": "1/200", "eta": "42 days, 20:36:11", "gpu_mem": "6.58G", "grad_norm": 185.14612, "iter": "209/1097", "loss": 1.71148, "lr": 0.00000, "top1_err": 100.00000, "top5_err": 0.00000}
